---
layout: post
comments: true
title: NeX novel view synthesis
author: Kevin Tang, Edmond Xie
date: 2022-01-28
---


> Novel view synthesis aims to generate a visual scene representation from just a sparse set of images and has a wide variety of uses in VR/AR. In this blog, we will explore and reproduce a new approach to this problem called NeX.



<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction
We will explore NeX, a new method of novel view synthesis that uses enhanced multiplane image (MPI) techniques to produce view-dependent effects in real-time.

## Implementation

## Demo 

## Reference

[1] Wizadwongsa, Suttisak, et al. "NeX: Real-time View Synthesis with Neural Basis Expansion" *arXiv preprint arXiv:2103.05606.* (2021).

[2] Zhou, Tinghui, et al. "Stereo Magnification: Learning view synthesis using multiplane images" *arXiv preprint arXiv:1805.09817* (2018).

[3] Ben Mildenhall, et al. "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis" *Proceedings of ECCV conference* (2020).

[4] Johannes Lutz Schonberger and Jan-Michael Frahm. "Structure-from-motion revisited." In Conference on Computer Vision and Pattern Recognition (CVPR), 2016. 

## Code Repository
[1] [NeX](https://github.com/nex-mpi/nex-code/)

[2] [Stereo Magnification](https://github.com/google/stereo-magnification)

[3] [NerF](https://github.com/bmild/nerf)

---
